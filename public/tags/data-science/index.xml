<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science | Anthony Schmidt</title>
    <link>https://anthonyschmidt.netlify.com/tags/data-science/</link>
      <atom:link href="https://anthonyschmidt.netlify.com/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    <description>Data Science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://anthonyschmidt.netlify.com/img/icon-192.png</url>
      <title>Data Science</title>
      <link>https://anthonyschmidt.netlify.com/tags/data-science/</link>
    </image>
    
    <item>
      <title>R Handbook for ESM Students</title>
      <link>https://anthonyschmidt.netlify.com/project/r-handbook/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/project/r-handbook/</guid>
      <description>&lt;p&gt;This is an ongoing project to write an introduction to R that is relevant to students in our evaluation, statistics, and measurement PhD program. It would also be relevant to those interested in learning R, especially for analyzing survey data from import, to cleaning, to analysis.&lt;/p&gt;

&lt;p&gt;The handbook is being developed with &lt;code&gt;bookdown&lt;/code&gt; and will have supplemental exercises written with &lt;code&gt;learnr&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Becoming “TidyR” over Time- Data Visualization Development in an Online Community of Practice</title>
      <link>https://anthonyschmidt.netlify.com/talk/2020-3-becoming-tidyr-over-time/</link>
      <pubDate>Wed, 11 Mar 2020 12:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/talk/2020-3-becoming-tidyr-over-time/</guid>
      <description>


&lt;div id=&#34;download-the-poster-here&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;a href=&#34;tidy_tuesday_poster.pdf&#34;&gt;Download the poster here!&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;This poster was designed using the #betterposter format. &lt;a href=&#34;https://twitter.com/mikemorrison/status/1110191245035479041?lang=en&#34;&gt;Click here to learn more.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;communities-of-practice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Communities of Practice&lt;/h2&gt;
&lt;p&gt;Communities of practice (CoPs) are groups of people who share a common interest and participate in activities that promote learning. Originally face-to-face, the internet has ushered in many new platforms for CoPs. Twitter hashtags act as virtual homes for many. The #TidyTuesday hashtag serves as a community for those interested in data science and visualization. It involves weekly visualization challenges utilizing public data sets and the R programming language. Users contribute graphics and code to share their work and also as opportunities to learn from one another. As the importance of data science grows, the #TidyTuesday CoP is a promising context for the exploration of learning in online communities and of how individuals develop capabilities regarding visualization and programming.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidytuesday&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;#TidyTuesday&lt;/h2&gt;
&lt;p&gt;Every Tuesday, a unique data set is posted on Twitter using the hashtag #TidyTuesday. Participants use the data set to create visualizations using R programming language and the Tidyverse packages. Participants then share their visualization on Twitter and link to their code (on Github). This is done not only to share their own work, but as chances to learn from each other. It is open to contributors of any skill level.&lt;/p&gt;
&lt;div id=&#34;tidytuesday-examples&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;#TidyTuesday Examples&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/ariamsita/status/1171421023838687232?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1171421023838687232&amp;ref_url=https%3A%2F%2Fnsgrantham.shinyapps.io%2Ftidytuesdayrocks%2F&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://pbs.twimg.com/media/EEG5NEMU4AUUNDF.jpg&#34; width=&#34;50%&#34; alt=&#34;@ariamsita&#34;/&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/jakekaupp/status/1161656332686102529?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1161656332686102529&amp;ref_url=https%3A%2F%2Fnsgrantham.shinyapps.io%2Ftidytuesdayrocks%2F&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://pbs.twimg.com/media/EB8IPOdXYAAjOd7.jpg&#34; width=&#34;50%&#34; alt=&#34;@jakekaupp&#34;/&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/geokaramanis/status/1164147090580267008?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1164500880177188864&amp;ref_url=https%3A%2F%2Fnsgrantham.shinyapps.io%2Ftidytuesdayrocks%2F&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://pbs.twimg.com/media/ECfhh7OX4AAGnO-.jpg&#34; width=&#34;50%&#34; alt=&#34;@geokarimanis&#34;/&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What is R?&lt;/h3&gt;
&lt;p&gt;R is a statistical programming language that is used for data analysis, modeling, machine learning, and data visualization. It has been around for over 20 years and has become a sought after programming language in data analysis, statistics, business analytics, and other fields. Below is an example of simple R code and a simple plot produced with this code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(ggplot2)

iris %&amp;gt;%
  ggplot() +
    geom_point(aes(x=Sepal.Length,y=Sepal.Width))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://anthonyschmidt.netlify.com/talk/2020-3-becoming-tidyr-over-time/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;research-purpose&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Research Purpose&lt;/h2&gt;
&lt;p&gt;The current research represents an exploratory project that examines one year of #TidyTuesday tweets through descriptive statistics, content analyses using the &lt;code&gt;TidyCode&lt;/code&gt; package, and qualitative coding in order to understand the activities and potential impacts of the #TidyTuesday CoP. It examines who contributes, the content of their tweets, the makeup of their code, and how their code changes over time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;findings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Findings&lt;/h2&gt;
&lt;p&gt;Data was pulled from &lt;a href=&#34;https://nsgrantham.shinyapps.io/tidytuesdayrocks/&#34;&gt;TidyTuesday Rocks&lt;/a&gt;, an interactive app that allows you to explore TidyTuesday contributions.&lt;/p&gt;
&lt;div id=&#34;descriptives&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Descriptives&lt;/h3&gt;
&lt;p&gt;There were &lt;strong&gt;4,418&lt;/strong&gt; tweets contributed to the data set.&lt;/p&gt;
&lt;p&gt;There were &lt;strong&gt;2,428&lt;/strong&gt; unique contributions to the data set.
* A contribution is any post that included an image.&lt;/p&gt;
&lt;p&gt;There were &lt;strong&gt;800&lt;/strong&gt; unique contributors.
* Contributors are those who tweeted some image during #TidyTuesday&lt;/p&gt;
&lt;p&gt;There were &lt;strong&gt;46.7&lt;/strong&gt; mean contributions per week.&lt;/p&gt;
&lt;p&gt;Each user contributed an average of &lt;strong&gt;5.93&lt;/strong&gt; times in one year.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;content-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Content Analysis&lt;/h3&gt;
&lt;p&gt;Along with their graphic visualizations, many contributors also share their code via Github. This allows others to reproduce contributors’ work, possibly aiding in data visualization skill development.&lt;/p&gt;
&lt;p&gt;Code from contributors’ Github repositories were scraped and subsequently analyzed using the &lt;a href=&#34;https://cran.r-project.org/web/packages/tidycode/index.html&#34;&gt;&lt;code&gt;TidyCode&lt;/code&gt;&lt;/a&gt; package. This package allows individual functions to be classified according to a crowd-sourced dictionary of R functions. These classifications include setup, import, export, data cleaning (encompassing data wrangling and munging), visualization, communication, modeling, exploration, and evaluation. The dictionary was modified to include non-classified functions and to reclassify functions based on the content of data visualization.&lt;/p&gt;
&lt;div id=&#34;functions-over-time&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Functions Over Time&lt;/h4&gt;
&lt;p&gt;First, the average number of functions were tweet number was analyzed. Tweet number represents each users unique contribution for that week. The analysis showed that over time the mean number of functions increase. This could suggest writing longer and more complex code, especially code that includes a larger variety of functions. A simple Pearson correlation between mean functions and tweet number also suggested that as tweet numbers increase, so do mean functions (&lt;em&gt;r&lt;/em&gt; = .54, &lt;em&gt;p&lt;/em&gt; &amp;lt; .001 - a medium correlation).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;mean%20functions.jpeg&#34; alt=&#34;Mean Functions&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Mean Functions&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;change-in-function-proportion&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Change in Function Proportion&lt;/h4&gt;
&lt;p&gt;An analysis of the proportion of functions by classification per week was also analyzed. This analysis focused on data cleaning, data visualization, and data communication. It showed that, while proportion fluctuates;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;communication&lt;/strong&gt; related functions are slowly increasing.
&lt;ul&gt;
&lt;li&gt;Communication functions are those that add a more textual, communicative layer to visualizations.&lt;/li&gt;
&lt;li&gt;These functions include &lt;code&gt;geom_label(), geom_curve(), str_wrap(), arrow()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;data cleaning&lt;/strong&gt; actually decreased over time, suggesting less pre-processing of data and the possibility of writing more efficient code that uses less functions.
&lt;ul&gt;
&lt;li&gt;These functions include &lt;code&gt;mutate(), filter(), case_when()&lt;/code&gt; and a variety of &lt;code&gt;join()&lt;/code&gt; functions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;visualization&lt;/strong&gt; functions remain relatively stable over time
&lt;ul&gt;
&lt;li&gt;These include functions like &lt;code&gt;theme(), geom_path(), aes(), facet_wrap()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;prop%20of%20code%20by%20function.jpeg&#34; alt=&#34;Proportion of Code&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Proportion of Code&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;qualitative-coding&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Qualitative Coding&lt;/h3&gt;
&lt;div id=&#34;tweets&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Tweets&lt;/h4&gt;
&lt;p&gt;150 random tweets (initial contributions) were samples from the data and coded. These codes were then used to reveal several themes in the tweets.&lt;/p&gt;
&lt;p&gt;It was found that a majority of tweets were visualization focused, either explaining the visualizations themselves (how they were made, what they looked at) or discussing interesting findings in the data.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;tweets.png&#34; alt=&#34;Qualitative Tweet Analysis&#34; width=&#34;300&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Qualitative Tweet Analysis&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Some examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Theme&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Explaining Data&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#TidyTuesday turned into tidy Saturday this week! Looking at plastic pollution around the globe. I made a waffle chart of the five countries with most mismanaged plastic waste.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Discussing Findings&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#tidytuesday I used to think all nobel peace price winners are grey old guys. Turns out, they are getting younger compared to the other folks.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Engaging Community&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;My #tidytuesday viz this week is inspired by awesome people who make scarves from data. Can’t knit, but I can geom_linerange&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Showing Emotion&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;First ever #TidyTuesday submission! I’ve always been reluctant to share, because I see so many great submissions. But today I’ve done some new cool things (first time I made a map in R!!) and I’m quite happy with the result.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;retweets&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Retweets&lt;/h4&gt;
&lt;p&gt;Likewise, 150 randomly sampled retweets were coded. Retweets were chosen as they can reveal how users are not only contributing to the #TidyTuesday challenge itself but how they are engaging with the community. Most retweets were simply promoting #TidyTuesday (e.g. “It’s #TidyTuesday yall!”)and these were removed from analysis as they were not seen as substantive. More substantive tweet content was found to mostly be about celebrating others’ work, related to their own learning via the community, or sharing the work of others.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;retweets.png&#34; alt=&#34;Retweets&#34; width=&#34;300&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Retweets&lt;/p&gt;
&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Theme&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Celebrating Others&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Jake’s dataviz work as part of #TidyTuesday is always beautiful. This one is especially great. Check out the legend he made using ggplot.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Learning&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Thanks to #TidyTuesday for making it so easy to learn/use #R and to get to know others! #grateful&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Sharing Others’ Visualizations&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;This thread highlights one of my favorite parts of #TidyTuesday, spontaneous and friendly collaboration!! Sara continues to do awesome deep dives on the #tidytuesday datasets! Lots of great content here and on her GitHub.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This preliminary research has education-related implications for those involved in data science. It suggests that participating in #TidyTuesday can help one develop their data visualization skills by learning from others’ visuals and code and by exercising one’s own skills. It also indicates that sustained participation can help increase the complexity of one’s code, the efficiency of one’s code, and the graphics produced may contain enhanced communicative ability.&lt;/p&gt;
&lt;p&gt;Further research will be used to verify and enhance these claims.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exploring #flyingless on Twitter with TAGS</title>
      <link>https://anthonyschmidt.netlify.com/post/exploring-flying-less-with-tags/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/post/exploring-flying-less-with-tags/</guid>
      <description>


&lt;p&gt;I recently started using &lt;a href=&#34;https://tags.hawksey.info/&#34;&gt;TAGS&lt;/a&gt; to start archiving Twitter posts with key search phrases for later exploration and possible research. One of my search phrases was the hashtag #flyingless. #flyingless typically is appended to posts related to reducing the carbon footprint associated with flying, often flying to and from conferences, but also flying in general.&lt;/p&gt;
&lt;p&gt;By just scraping the past few days worth of data, I found a few interesting takeaways.&lt;/p&gt;
&lt;div id=&#34;policies-and-guides&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Policies and Guides&lt;/h1&gt;
&lt;p&gt;Fundings organizations are taking the carbon footprint of their funds into account. This is from the UK, but maybe we will see similar things from NSF or NIH?&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/jamesryle/status/1232612369265721345&#34;&gt;&lt;img src=&#34;1232612369265721345.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The University of Santa Barbara is also promoting smaller carbon footprints with their &lt;a href=&#34;http://hiltner.english.ucsb.edu/index.php/ncnc-guide/&#34;&gt;Nearly Carbon-Neutral Conference Model Guide&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/EINS78/status/1233111821495754752&#34;&gt;&lt;img src=&#34;1233111821495754752.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conferences-are-paying-attention&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conferences Are Paying Attention&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/AntoniaSladek/status/1230871054387687424&#34;&gt;&lt;img src=&#34;1230871054387687424.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/sachbon/status/1232408500178956290&#34;&gt;&lt;img src=&#34;1232408500178956290.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;there-is-some-good-research-about-flyingless&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;There is some good research about #flyingless&lt;/h1&gt;
&lt;p&gt;I learned about &lt;a href=&#34;https://openresearch-repository.anu.edu.au/bitstream/1885/13949/1/Young%20et%20al%20Flights%20of%20Fantasy%202015.pdf&#34;&gt;&lt;em&gt;Flights of fantasy: A reformulation of the flyers’ dilemma&lt;/em&gt;&lt;/a&gt; by Young, M., Markham, F., Reis, A. C., &amp;amp; Higham, J. E. (2015).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;httpstwitter.comTheGroundedProjstatus1233391406820904960&#34;&gt;&lt;img src=&#34;1233391406820904960.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And this master’s thesis by Lisa Jacobson, &lt;a href=&#34;http://www.diva-portal.org/smash/get/diva2:1221346/FULLTEXT01.pdf&#34;&gt;&lt;em&gt;Transforming air travel behavior
in the face of climate change: Incentives and barriers in a Swedish setting&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://twitter.com/KA_Nicholas/statuses/1233771519433695232&#34;&gt;&lt;img src=&#34;1233771519433695232.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;people-are-enjoying-flyingless&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;People are enjoying #flyingless&lt;/h1&gt;
&lt;p&gt;People are sharing their #flyingless routes and the joy of slow travel. These mostly seem to be from Europe, where they can take advantage of modern rail travel.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/bestdeadends/status/1231234246444015619&#34;&gt;&lt;img src=&#34;1231234246444015619.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://twitter.com/steinarhoiback/statuses/1231490161739018240&#34;&gt;&lt;img src=&#34;1231490161739018240.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://twitter.com/SlowTravelStays/statuses/1232347841886072834&#34;&gt;&lt;img src=&#34;1232347841886072834.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tags-is-really-cool&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;TAGS is really cool!&lt;/h1&gt;
&lt;p&gt;The functionality is really great, as it now only scrapes Twitter from the present to the past 7 days, but you can also ask it to scrape every hour until a maximum amount of Tweets is reached (you set the maximum). It also auto-produces a cool interative dashboard you can play with to explore Twitter users and their tweets in the datset. &lt;a href=&#34;https://hawksey.info/tagsexplorer/?key=1CrSy6fhs9x9cadgMLjPJuzfh5C7c5G3_3AMVRiwd1EM&amp;amp;gid=400689247&#34;&gt;&lt;em&gt;Click here to check out the dashboard related to my #flyingless TAGS.&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are wondering what you can do with all this Twitter data, I highly recommend checking out the online book &lt;a href=&#34;https://www.tidytextmining.com/&#34;&gt;&lt;em&gt;Text Mining with R&lt;/em&gt;&lt;/a&gt;. It’s actually incredibly easy and really fun!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Carbon Crisis Mitigation: Whose Responsibility Is It? - A #TidyTuesday-inspired Essay</title>
      <link>https://anthonyschmidt.netlify.com/post/2020-19-02-carbon-crisis-mitigation-whose-responsibility-is-it-a-tidytuesday-inspired-essay/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/post/2020-19-02-carbon-crisis-mitigation-whose-responsibility-is-it-a-tidytuesday-inspired-essay/</guid>
      <description>


&lt;p&gt;After a long hiatus, I decided to participate in this week’s #TidyTuesday on Twitter. The data set was from &lt;a href=&#34;https://www.nu3.de/blogs/nutrition/food-carbon-footprint-index-2018&#34;&gt;nu3.de&lt;/a&gt; and focused on the 2018 carbon footprint of food based on individual country’s consumption of beef, pork, chicken, eggs, nuts, grains, etc. I produced a map of total food-based carbon emissions:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;tilemap.png&#34;&gt;&lt;img src=&#34;tilemap.png&#34; alt=&#34;My #TidyTuesday Tilemap&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This small project got me thinking about the United States, its disproportionate contribution to the climate crisis, and how changing our personal habits may have a positive change.&lt;/p&gt;
&lt;p&gt;According to the data set, the US is 6th out of over 130 countries in terms of its food-based carbon footprint, and among the different food groups, the largest emissions are due to the consumption of beef.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://anthonyschmidt.netlify.com/post/2020-19-02-carbon-crisis-mitigation-whose-responsibility-is-it-a-tidytuesday-inspired-essay/index_files/figure-html/data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Why is beef such a carbon-intensive food? Beef requires more land - land for raising cows and land required to grow the grain to feed them - and more resources overall. According to an article from the &lt;a href=&#34;https://www.smithsonianmag.com/science-nature/beef-uses-ten-times-more-resources-poultry-dairy-eggs-pork-180952103/&#34;&gt;&lt;em&gt;Smithsonian&lt;/em&gt;&lt;/a&gt;, “beef requires 28 times more land, six times more fertilizer and 11 times more water compared to those other food sources. That adds up to about five times more greenhouse gas emissions.” In addition, the &lt;a href=&#34;https://www.npr.org/sections/thesalt/2014/04/11/301794415/gassy-cows-are-warming-the-planet-and-theyre-here-to-stay&#34;&gt;methane released from cows&lt;/a&gt; increase the already high carbon footprint.&lt;/p&gt;
&lt;p&gt;This had me wondering: if beef has such a large carbon footprint, what impact would a reduction in beef consumption have? It also led to a deeper question: can individual changes really help mitigate climate change?&lt;/p&gt;
&lt;div id=&#34;eat-less-beef&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Eat Less Beef?&lt;/h2&gt;
&lt;p&gt;The data above indicates Americans eat 36.24kg of beef per person per year, which equates to 1118.29 kg/CO&lt;sub&gt;2&lt;/sub&gt; per person per year. Of course, this is just the average. Some eat more, some eat less or none at all. According to the &lt;a href=&#34;https://www.census.gov/popclock/&#34;&gt;US Census Population Clock&lt;/a&gt;, there were 329,302,971 people in the US on February 19, 2020. Let’s trim 5% off of that figure to account for the extremely young and old, and another 4% to account for &lt;a href=&#34;https://en.wikipedia.org/wiki/Vegetarianism_by_country&#34;&gt;the number of vegetarians and vegans in the us&lt;/a&gt;. That leaves
an estimated beef-consuming US population of 299,665,704 people. Using the emissions figure above, the beef-related emissions of these people equals 335,113,160,126 kg/CO&lt;sub&gt;2&lt;/sub&gt;/year, or, &lt;strong&gt;335,113,160 metric tons of CO&lt;sub&gt;2&lt;/sub&gt; each year&lt;/strong&gt;. According to the &lt;a href=&#34;http://folk.uio.no/roberan/img/GCB2019/PNG/s15_2019_Top_FF_emitters_abs.png&#34;&gt;Global Carbon Project&lt;/a&gt;, the US emitted 5,400,000,000 metric tons of CO&lt;sub&gt;2&lt;/sub&gt; in 2018. This means that beef emissions account for 6.2% of total US emissions.&lt;/p&gt;
&lt;p&gt;Is 6% of our carbon footprint a big deal? Well, consider that this is just 6% of emissions based solely on &lt;strong&gt;one&lt;/strong&gt; food that we eat. In that case, it is quite a bit! So, if we did reduce our beef consumption, what kind of effect would it have?&lt;/p&gt;
&lt;p&gt;The following chart shows the amount of emissions if we reduce our consumption of beef by 10%, 20%, all the way to 100%. It shows a 10% reduction has a carbon footprint of 5.8%. A 50% reduction of beef consumption equates to our habits contributing only 3.1% of the US carbon footprint. This small percentage is &lt;strong&gt;not negligible&lt;/strong&gt; when you consider that we need to reduce our emissions by &lt;a href=&#34;https://www.ipcc.ch/2018/10/08/summary-for-policymakers-of-ipcc-special-report-on-global-warming-of-1-5c-approved-by-governments/&#34;&gt;45% overall&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://anthonyschmidt.netlify.com/post/2020-19-02-carbon-crisis-mitigation-whose-responsibility-is-it-a-tidytuesday-inspired-essay/index_files/figure-html/reduction-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;whose-responsibility&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Whose Responsibility?&lt;/h2&gt;
&lt;p&gt;The above indicates that a small change in our eating habits &lt;em&gt;may&lt;/em&gt; make &lt;em&gt;some&lt;/em&gt; impact on the planet. These hedges are hard not to notice: &lt;em&gt;May&lt;/em&gt; and &lt;em&gt;some&lt;/em&gt;. These reduced impacts assume 1) that everyone will do it, and 2) that individual changes are the root cause of and therefore the solution to the climate crisis.&lt;/p&gt;
&lt;p&gt;The EPA says that about 24% of US emissions stem from agriculture (a 50% reduction in beef consumption could reduce that to less than 21%).&lt;/p&gt;
&lt;p&gt;But, near equal amounts of emissions come from industry and electricity. Within electricity generation, almost 70% is from industry, transportation, or agriculture. In other words, these emissions are not necessarily caused by individual habits.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.epa.gov/sites/production/files/styles/medium/public/2016-05/global_emissions_sector_2015.png&#34; alt=&#34;Global Greenhouse Emissions by Sector&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Global Greenhouse Emissions by Sector&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.epa.gov/sites/production/files/styles/medium/public/2019-04/total-2019.jpg&#34; alt=&#34;US Greenhouse Emissions of Electricity&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;US Greenhouse Emissions of Electricity&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In a sense, most emissions are not caused by individuals. Rather, these emissions are generated by government and business. This begs the question of whether it is fair or practical to ask individuals to alter their lifestyle to avert the climate crisis.&lt;/p&gt;
&lt;p&gt;Here, we seem to run into an argument that requires mathematical and moral reasoning.&lt;/p&gt;
&lt;div id=&#34;mathematical-reasoning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mathematical Reasoning&lt;/h3&gt;
&lt;p&gt;Recall that if we reduce our beef consumption by 50%, we also reduce our emissions from 6.2% to 3.1%. Recall, also, that this is from one* single food source*. Reducing other meat products will lead to other emissions reductions and &lt;a href=&#34;https://www.accuweather.com/en/weather-news/how-plant-based-diets-can-help-reduce-greenhouse-gas-emissions-by-70-percent/351781&#34;&gt;a shift to a plant-based diet can reduce emissions by 70%&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Asking everyone to be a vegetarian is a radical concept. Asking people to &lt;em&gt;reduce&lt;/em&gt; (when financially or physically possible) their meat consumption is not. This small change adds certainly has a positive effect and gets us closer to the target of reducing our emissions by 45% by 2030 to stave off warming over 2 degrees.&lt;/p&gt;
&lt;p&gt;We can make other changes in our energy consumption and travelling habits, too. But, wait, is it fair to ask the average American to “give up” hamburgers, shell out extra money on energy efficient appliances, and stop flying around the world (flying only contributes about 4.5% to anthropogenic climate change)?&lt;/p&gt;
&lt;p&gt;How is this fair when its government and business driving the climate crisis? Also, how is it fair to ask people to make this kind of sacrifice when they know that the people around them will not? Also, how is it fair to ask people to stop doing these ordinary things that have suddenly become dirty and the cause for climate shame?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moral-reasoning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Moral Reasoning&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;For this section, I am drawing heavily on &lt;a href=&#34;https://link.springer.com/article/10.1007/s10677-019-09995-5&#34;&gt;Peeters et al. (2018)&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Yes, as individuals, our contributions are minuscule. However, they are &lt;strong&gt;real&lt;/strong&gt;. One issue is that our individual actions do not directly translate into visible harm and are thought of as future effects and thus easier to disassociate from. However, the climate crisis is not an event in the future, it is already happening: glaciers are melting faster, there are increases in wildfires, storms are intensifying, and low-lying island land is receding. Therefore, our continued contribution as individuals accumulates and exacerbates these issues.&lt;/p&gt;
&lt;p&gt;However, even if we make a person change, others may not. This is an inherent dilemma when a problem is caused collectively. The idea is that “No one needs to change until after everyone else changes” (Shue, 1996, p. 112-13). The responsibly gets passed to other people and the solution is undermined by this inaction. The fact is, other people may not change. However, because the climate crisis is both individual- and collectively caused, others’ inaction is no excuse for one’s own inaction.&lt;/p&gt;
&lt;p&gt;The reasoning above assumes, others will not change. However, this is not always the case. One’s own individual changes may be mathematically small but can be symbolically profound. That is, our actions serve a symbolic role and can definitely influence others. For example, research has found a clear “neighbor effect” for solar panels, finding that installation of solar panels influences others to do so (&lt;a href=&#34;https://link.springer.com/article/10.1007/s10018-019-00239-5&#34;&gt;Kosugi et. al, 2019&lt;/a&gt;; &lt;a href=&#34;https://www.theatlantic.com/magazine/archive/2020/03/climate-change-peer-pressure/605515/&#34;&gt;Frank, 2020&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;To that end, raising awareness and advocating for change (at school, at work, among family and friends) is another action that can be taken in addition to personal changes.&lt;/p&gt;
&lt;p&gt;Unfortunately, we still have several other issues to deal with. One is why is it fair to ask people to stop doing the ordinary things they have always done just because these things have suddenly become associated with the climate crisis. First, as Peeters et al. (2018) point out, “The mere fact that many other people engage in an act does not render it harmless” (p. 433). In addition, what we consider ordinary or usual is certainly not so. Take our beef consumption habits. We are sixth in terms of per capita emissions - sixth out of 130 countries. The beef emissions of the United States equate to the same emissions, per capita, as the bottom 17 countries on beef consumption combined.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://anthonyschmidt.netlify.com/post/2020-19-02-carbon-crisis-mitigation-whose-responsibility-is-it-a-tidytuesday-inspired-essay/index_files/figure-html/bottom_countries-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our habits - eating beef, jet-setting around the world, hot showers several times a day, joyriding, leaving the lights on - are certainly normal to us, but around the world, they are matter of factly not the norm. The western world contains around 15% of the world’s population, yet has dissproportionatley contributed to the climate crisis through habits it considers ordinary but are in fact unique. These three charts illustrate this:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;totalemissions.png&#34; alt=&#34;A Map of Total Emissions&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;A Map of Total Emissions&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://www.viewsoftheworld.net/wp-content/uploads/2010/11/CarbonEmissionMap_2009.jpg&#34; alt=&#34;A Cartogram of Global CO2 Emissions&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;A Cartogram of Global CO2 Emissions&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/1/15/World_fossil_carbon_dioxide_emissions_six_top_countries_and_confederations.png&#34; alt=&#34;A Timeline of CO2 Emissions - And Its Largest Contributors&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;A Timeline of CO2 Emissions - And Its Largest Contributors&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As Peeters et al. (2018) point out, our actions are ordinary in our local contexts, but unusual in a global context. Since the climate crisis is a global crisis, it is imperative to consider this global context.&lt;/p&gt;
&lt;p&gt;The irony here is that the western world is driving climate change, but the effects will be mostly felt by those whose carbon footprints are dwarfed by our own - countries mainly in the global south.&lt;/p&gt;
&lt;p&gt;As George Bush Sr. once &lt;a href=&#34;http://www.ipsnews.net/2012/05/us-lifestyle-is-not-up-for-negotiation/&#34;&gt;declared&lt;/a&gt; at the 1992 Earth Summit in Rio de Janeiro, “The American way of life is not up for negotiations. Period.”&lt;/p&gt;
&lt;p&gt;Well, if the American way of life is both unusual in the global context and unfairly contributing to the climate crisis, there is a moral imperative that it should be up for “negotiation.” And that negotiation does not really mean any radical individual changes: for those who are financially able, it means a reduction in meat consumption, conservation of energy, carefully considering air travel, and, again when financially feasible, investing in renewable energy.&lt;/p&gt;
&lt;p&gt;A final idea to deal with is the fact that government and business contribute much more to climate change than individuals. How can our personal changes make any effect when industry emits so much, and government is not investing enough in renewables?&lt;/p&gt;
&lt;p&gt;Well, we vote. Choose local, state, and national politicians who have a genuine concern about the crisis. Next, we vote…with out wallets. As consumers, we drive supply and demand. If we can shift our consumer habits - purchasing less beef, purchasing fuel-efficient or EV vehicles, buying renewable energy power blocks from our utilities, taking less flights - we can have a positive effect on industry. They may produce all the fossil fuels, but we burn them (&lt;a href=&#34;https://www.vox.com/the-goods/2018/10/12/17967738/climate-change-consumer-choices-green-renewable-energy&#34;&gt;Del Valle, 2018&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Individual changes can have both practical and symbolic effects. We can make an impact on our national and global carbon footprints while influencing others to do the same. We can advocate for change in government and be conscious consumers. Climate change is a complex problem, and requires solutions from every angle. As individuals, we can make a difference.&lt;/p&gt;
&lt;p&gt;I’ll leave the last words to Jamieson (2006, cited in Peeters et. al):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We must begin from where we are – changing ourselves, changing our leaders, and changing our institutions – but from here we can change the world. Biking instead of driving or choosing the veggieburger rather than the hamburger may seem like small choices, and it may seem that such small choices by such little people barely matter. But ironically, they may be the only thing that matters. For large changes are caused and constituted by small choices. And in the end, however things turn out, it is how we live that gives meaning and significance to our lives.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Assessing Your Carbon Footprint with Google Location Data</title>
      <link>https://anthonyschmidt.netlify.com/post/2020-02-10-carbon-footprint-google-data/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/post/2020-02-10-carbon-footprint-google-data/</guid>
      <description>

&lt;p&gt;Google collects &lt;em&gt;a lot&lt;/em&gt; of data on us. If you have Google Maps, chances are your location is being tracked, too. Unless, of course, you have it disabled. But, if you don&amp;rsquo;t, you&amp;rsquo;d be surprised by the amount of location data (and its accuracy) contained in your Google Timeline. &lt;a href=&#34;https://www.nytimes.com/interactive/2019/12/19/opinion/location-tracking-cell-phone.html&#34; target=&#34;_blank&#34;&gt;Many worry about Google&amp;rsquo;s tracking&lt;/a&gt;, but for those of us who don&amp;rsquo;t, there is some potential fun we can have with our own data.&lt;/p&gt;

&lt;p&gt;For example, we can &lt;strong&gt;estimate&lt;/strong&gt; our carbon emissions. I say &lt;strong&gt;estimate&lt;/strong&gt; because it is not exact and it is likely very difficult to account for (or even remember) all of your trips, who was with you, and how to split your emissions. Was your flight full? How &amp;ldquo;clean&amp;rdquo; was the train? How much of an Uber trip&amp;rsquo;s emissions count for you vs the driver?&lt;/p&gt;

&lt;p&gt;Those are difficult questions, and the real answer is elusive. But, we can come close. Using Google Location data, We can get the date and time of travel, start and end location, the distance traveled, the place, and most importantly, the activity type.&lt;/p&gt;

&lt;p&gt;Follow along and I&amp;rsquo;ll show you what I did. It&amp;rsquo;s no doubt imperfect, but for a beginner&amp;rsquo;s effort, I&amp;rsquo;d say it&amp;rsquo;s not too bad.&lt;/p&gt;

&lt;h1 id=&#34;get-your-data&#34;&gt;Get Your Data&lt;/h1&gt;

&lt;p&gt;Navigate to &lt;a href=&#34;https://takeout.google.com/?pli=1&#34; target=&#34;_blank&#34;&gt;Google Takeout&lt;/a&gt;, and first click &amp;ldquo;Deselect all&amp;rdquo; at the right. Then, scroll down to &amp;ldquo;Location History&amp;rdquo; and click on &amp;ldquo;Multiple Formats&amp;rdquo;. Choose JSON and click &amp;ldquo;OK&amp;rdquo;. Check the checkbox and scroll down to the bottom. Select &amp;ldquo;Next step&amp;rdquo;. Here you can export your data once or set a schedule. Click &amp;ldquo;create export&amp;rdquo;. Dependning on the amount of data, the export can take a few minutes (or &amp;ldquo;days&amp;rdquo; as Google claims). I got a year&amp;rsquo;s worth of data in about 3 minutes. Just refresh the page to check on the status.&lt;/p&gt;

&lt;p&gt;When its ready, download your zip file. Extract your zip file somewhere convenient. Drill into the extracted folder until you find &amp;ldquo;Semantic Location Data&amp;rdquo;. That is what we are after. This will contain a folder for each year and a JSON file for each month in that year.&lt;/p&gt;

&lt;h1 id=&#34;load-and-process&#34;&gt;Load and Process&lt;/h1&gt;

&lt;p&gt;You&amp;rsquo;ll need at minimum the following packages&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;jsonlite&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tidyverse&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lubridate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;load-data&#34;&gt;Load Data&lt;/h2&gt;

&lt;p&gt;You can load your data like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df &amp;lt;- data.frame(fromJSON(&amp;quot;file location/file&amp;quot;, flatten=TRUE))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JSON comes as a list format. I have no clue how to work with lists. So, I flattened it out to a data frame. I know how to work with those.&lt;/p&gt;

&lt;p&gt;I was going to write a for-loop to process the file list and automatically load the data, but since I was only working with 12 files (2019), I just did it like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jan2019 &amp;lt;- data.frame(fromJSON(&amp;quot;2019/2019_JANUARY.json&amp;quot;, flatten = TRUE))
feb2019 &amp;lt;- data.frame(fromJSON(&amp;quot;2019/2019_FEBRUARY.json&amp;quot;, flatten = TRUE))
mar2019 &amp;lt;- data.frame(fromJSON(&amp;quot;2019/2019_MARCH.json&amp;quot;, flatten = TRUE))
april2019 &amp;lt;- data.frame(fromJSON(&amp;quot;2019/2019_APRIL.json&amp;quot;, flatten = TRUE))
may2019 &amp;lt;- data.frame(fromJSON(&amp;quot;2019/2019_MAY.json&amp;quot;, flatten = TRUE))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;and so on.&lt;/p&gt;

&lt;h2 id=&#34;process-data&#34;&gt;Process Data&lt;/h2&gt;

&lt;p&gt;I thought I would simply &lt;code&gt;rbind&lt;/code&gt; the data and work with a single large data set, but many files had different numbers of columns, making it difficult to use &lt;code&gt;rbind&lt;/code&gt;. Thankfully, the data sets had the same variable names, so I wrote a function to process the data, selecting the variables I wanted and making a few changes (see &lt;a href=&#34;#function&#34;&gt;below&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;become-familiar-with-the-variables&#34;&gt;Become Familiar with the Variables&lt;/h2&gt;

&lt;p&gt;Before processing the data, you should become familiar with the column names and what you may want to focus on. There are &lt;em&gt;a lot&lt;/em&gt; of variables in the JSON file. There are variables for start and end location, path variables, distance, place name, accuracy estimates, etc. Here are the ones I was most interested in:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;timelineObjects.activitySegment.distance

&lt;ul&gt;
&lt;li&gt;distance travelled in feet&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;timelineObjects.activitySegment.activityType

&lt;ul&gt;
&lt;li&gt;flying, walking, in a car, on a train, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;timelineObjects.activitySegment.startLocation.latitudeE7 and timelineObjects.activitySegment.startLocation.longitudeE7

&lt;ul&gt;
&lt;li&gt;starting location&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;timelineObjects.activitySegment.endLocation.latitudeE7 and timelineObjects.activitySegment.endLocation.longitudeE7

&lt;ul&gt;
&lt;li&gt;ending location&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;timelineObjects.placeVisit.location.name

&lt;ul&gt;
&lt;li&gt;the place I went to&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;timelineObjects.placeVisit.duration.startTimestampMs

&lt;ul&gt;
&lt;li&gt;the start time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks to &lt;a href=&#34;https://shiring.github.io/maps/2016/12/30/Standortverlauf_post&#34; target=&#34;_blank&#34;&gt;Shirin&amp;rsquo;s playgRound&lt;/a&gt;, I had some clues about what to process in R, namely:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How to convert long/late from IE7 to GPS (divide by &lt;code&gt;1e7&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;How to convert time from POSIX milliseconds to human readable time &lt;code&gt;as.POSIXct(as.numeric(time_variable)/1000, origin = &amp;quot;1970-01-01&amp;quot;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One problem I noticed was that many rows were offset, meaning data was split between two or three rows. For example, time might have been in row 1 and location, and activity were in the next row. Sometimes, it was three rows. I used &lt;code&gt;lead()&lt;/code&gt; to grab data from the next row, and &lt;code&gt;zoo::na.locf()&lt;/code&gt; to grab data from the last non-empty row when &lt;code&gt;lead()&lt;/code&gt; wouldn&amp;rsquo;t do the trick. This is not a perfect solution and no doubt cause some minor innacurrcies, but for the most part, for such a large data set, it seemed to do the trick.&lt;/p&gt;

&lt;h2 id=&#34;function&#34;&gt;Select and Mutate&lt;/h2&gt;

&lt;p&gt;The following function selects key variables and then mutates them, creating variables with human-readable names. It also converts the distance to miles and kilometers. You could take it a step further and then select only those variables, dropping the original JSON columns, but I decided to leave them in out of laziness.&lt;/p&gt;

&lt;p&gt;The function takes a data frame name as its only input.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;##process data function
json_process &amp;lt;- function(dfin){
  dfin %&amp;gt;% select(timelineObjects.activitySegment.distance,
                  timelineObjects.activitySegment.activityType,
                  timelineObjects.activitySegment.startLocation.latitudeE7,
                  timelineObjects.activitySegment.startLocation.longitudeE7,
                  timelineObjects.activitySegment.endLocation.latitudeE7,
                  timelineObjects.activitySegment.endLocation.longitudeE7,
                  timelineObjects.placeVisit.location.name,
                  timelineObjects.placeVisit.duration.startTimestampMs) %&amp;gt;%
    mutate(
      start_lat = timelineObjects.activitySegment.startLocation.latitudeE7 / 1e7,
      star_long = timelineObjects.activitySegment.startLocation.longitudeE7 / 1e7,
      end_lat = timelineObjects.activitySegment.endLocation.latitudeE7 / 1e7,
      end_long = timelineObjects.activitySegment.endLocation.longitudeE7 / 1e7,
      time = lead(as.POSIXct(as.numeric(timelineObjects.placeVisit.duration.startTimestampMs)/1000, origin = &amp;quot;1970-01-01&amp;quot;), 3L),
      year = year(time),
      month = ifelse(is.na(time), month(zoo::na.locf(time)), month(time)),
      activity = ifelse(is.na(timelineObjects.activitySegment.activityType), zoo::na.locf(timelineObjects.activitySegment.activityType), timelineObjects.activitySegment.activityType),
      place = lead(timelineObjects.placeVisit.location.name, 3L),
      miles = timelineObjects.activitySegment.distance/1609,
      km = timelineObjects.activitySegment.distance/1000)
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I called the function like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jan &amp;lt;- json_process(jan2019)
feb &amp;lt;- json_process(feb2019)
mar &amp;lt;- json_process(mar2019)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then combined the data frames:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;lt;- rbind(jan, feb, mar, april, may, june, july, aug, sep, oct, nov, dec)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;analyze-and-visualize&#34;&gt;Analyze and Visualize&lt;/h1&gt;

&lt;p&gt;First, you should check what activities are listed in your data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data %&amp;gt;% group_by(activity) %&amp;gt;% count
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The activities included FLYING, IN_FERRY, IN_BUS, IN_SUBWAY, etc. However, I focused on only two carbon-emitting activities in my data - those that I could easily account carbon emissions for - and created a small data frame to use for filtering:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;carbon_activities &amp;lt;- data.frame(activity = c(&amp;quot;FLYING&amp;quot;,
                              &amp;quot;IN_PASSENGER_VEHICLE&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I then created a new data frame that dropped missing values, selected only flying and car activities, and then calculated emissions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;prep &amp;lt;- data %&amp;gt;% drop_na(activity) %&amp;gt;%
  filter(activity %in% carbon_activities$activity) %&amp;gt;%
  mutate(
    emissions = ifelse(activity == &amp;quot;FLYING&amp;quot;, km*.18, km*.14)
  ) %&amp;gt;% drop_na(emissions)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How did I get the figures for emissions? Well, it turns out that calculating carbon emissions from flying is quite difficult. Here are some notes from the &lt;a href=&#34;https://www.icao.int/environmental-protection/Carbonoffset/Pages/default.aspx&#34; target=&#34;_blank&#34;&gt;ICAO website&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Step 1: Estimation of the aircraft fuel burn&lt;/li&gt;
&lt;li&gt;Step 2: Calculation of the passengers&amp;rsquo; fuel burn based on a passenger/freight factor which is derived from RTK data&lt;/li&gt;
&lt;li&gt;Step 3: Calculation of seats occupied (assumption: all aircraft are entirely configured with economic seats). Seat occupied = Total seats x Load Factor&lt;/li&gt;
&lt;li&gt;Step 4: CO2 emissions per passenger = (Passengers&amp;rsquo; fuel burn x 3.16) / Seat occupied&lt;/li&gt;
&lt;li&gt;Note: for flights above 3000 km, CO2 emissions per passenger in premium cabin = 2 x CO2 emissions per passenger in economy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Their &lt;a href=&#34;https://www.icao.int/environmental-protection/CarbonOffset/Documents/Methodology%20ICAO%20Carbon%20Calculator_v10-2017.pdf&#34; target=&#34;_blank&#34;&gt;methodology paper&lt;/a&gt; &lt;em&gt;probably&lt;/em&gt; has enough of this information, including numerous tables, to make these calculations. While I intend to make a better attempt at this in the future, using some suggestions from &lt;a href=&#34;https://sheilasaia.rbind.io/post/2019-04-19-carbon-cost-calcs/&#34; target=&#34;_blank&#34;&gt;Sheila Saia&lt;/a&gt; I just wanted a rough, liberal estimate of my emissions.&lt;/p&gt;

&lt;p&gt;I found &lt;a href=&#34;https://www.eci.ox.ac.uk/research/energy/downloads/jardine09-carboninflights.pdf&#34; target=&#34;_blank&#34;&gt;this paper from the Environmental Change Institute&lt;/a&gt;, which explained several different methods of calculation. The simplest is based on the World Resource Institute&amp;rsquo;s liberal estimate of 0.18 kgCO2/km. I chose this because it was simple to calculate.&lt;/p&gt;

&lt;p&gt;For driving, I used &lt;a href=&#34;https://www.carbonfootprint.com/calculator.aspx&#34; target=&#34;_blank&#34;&gt;this online carbon footprint calculator&lt;/a&gt;. I selected &amp;ldquo;Car&amp;rdquo;, entered in 1000km and my car&amp;rsquo;s average MPG (38MPG - though I often get 40-45 on longer trips), and the result was &amp;ldquo;0.14 metric tons:  1000 km in a petrol vehicle doing 38 mpg (US).&amp;rdquo; That is, 140 kgCO2/1000 km, which is the same as .14 kgCO2/km.&lt;/p&gt;

&lt;p&gt;Finally, I can visualize the result:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;prep %&amp;gt;%
  group_by(month, activity) %&amp;gt;%
  summarize(sum = sum(emissions)) %&amp;gt;%
  ggplot()+
  geom_bar(aes(x=as.factor(month), y=sum, fill=activity), stat=&amp;quot;identity&amp;quot;)+
  #facet_wrap(~activity, scales=&amp;quot;free&amp;quot;)+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))+
  labs(title = &amp;quot;Personal CO2 Emissions from Transportation&amp;quot;,
       caption = &amp;quot;kgC02/km for flights calculated based on liberal WRI estimate: km * .18. \nkgCO2/km for car calculated based on .14kg per 1000km&amp;quot;,
       x = &amp;quot;Month&amp;quot;,
       y = &amp;quot;kgCO2&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://anthonyschmidt.netlify.com/post/2020-02-10-carbon-footprint-google-data/personal-emissions.png&#34; alt=&#34;My Personal Emissions - 2019&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;This is a just a simple example of what one can do with their location data. I will be using my data in an interactive Tableau dashboard that also includes utility usage and will allow me to drill down by month, day, and hour. It will also allow me to compare my 2020 emissions to 2019. &lt;strong&gt;My goal is to have lower emissions.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I think there are a lot of possibilities with Google Location data (for tracking carbon emissions, for making cool visualizations), and even with liberal estimates of kgCO2, you still get a sense of your impact and have a visual goal you can compare against for the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data-Related Jobs for ESM Students</title>
      <link>https://anthonyschmidt.netlify.com/project/esm-data-jobs/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/project/esm-data-jobs/</guid>
      <description>&lt;p&gt;This is an ongoing project to analyze data-related jobs posted on &lt;a href=&#34;http://www.higheredjobs.com&#34; target=&#34;_blank&#34;&gt;HigherEdJobs&lt;/a&gt;. These are jobs a typical ESM student would qualify. The jobs are analyzed in order to understand the skills and competencies that are in demand.&lt;/p&gt;

&lt;p&gt;The project is currently focused on administrative-level jobs. Faculty job analyses will be forthcoming.&lt;/p&gt;

&lt;p&gt;The project files can be found on Github &lt;a href=&#34;https://github.com/acircleda/Data-Jobs&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. The analyses, always under development, can be found &lt;a href=&#34;https://acircleda.github.io/Data-Jobs/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Becoming Tidyr over Time</title>
      <link>https://anthonyschmidt.netlify.com/project/tidy-tuesday/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/project/tidy-tuesday/</guid>
      <description>&lt;p&gt;This project analyzes tweets from the #TidyTuesday hashtag to understand participation and development of data visualization and data science skills.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Speaking of Data</title>
      <link>https://anthonyschmidt.netlify.com/post/2019-08-24-speaking-of-data/</link>
      <pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://anthonyschmidt.netlify.com/post/2019-08-24-speaking-of-data/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Read this aloud: “We need more data.”&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;How did you pronounce the word “data”? Was the “da” in data pronounced like day or was the “a” in “da” pronounced with the same “a” as in apple? In other words, do you say day-tuh (IPA: /deɪtə/) or dah-tuh (IPA: /dætə/; like the “a” in “apple”)?&lt;/p&gt;

&lt;p&gt;Two things got me thinking about this. First, there was a brief &lt;a href=&#34;https://boingboing.net/2019/08/14/brent-spiner-explains-how-patr.html&#34; target=&#34;_blank&#34;&gt;article&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=xeqTMTOxid8&#34; target=&#34;_blank&#34;&gt;video&lt;/a&gt; that popped up on Twitter arguing that the creation of the character “Data” from Star Trek shifted the pronunciation of the word from /dætə/ to /deɪtə/. I’m not sure I believe this, but it did make me wonder when and why the schism or shift occurred.&lt;/p&gt;

&lt;p&gt;Second, my new role as data visualization researcher had me thinking about how exactly I pronounce my title. Unconsciously, I default to /dætə/. However, when I begin to think about the word and say examples aloud, it seems my pronunciation vacillates between the two.&lt;/p&gt;

&lt;p&gt;While I have no doubt that both pronunciations are “correct” and common, I did wonder which one was more common. I formulated several hypotheses and then developed a method to attempt to test them. I don’t claim that any of this is scientific, but it was really fun!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HYPOTHESES&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Given that I straddle the line between Gen Xer and Millennial, it is likely my pronunciation of data as /dætə/ is more common. This is just the phenomenon that occurs with my and the next generation. Therefore, younger people will be more likely to say /dætə/.&lt;/li&gt;
&lt;li&gt;/dætə/ or perhaps /da:tə/ will be more common in British English than /deɪtə/, which will be more common in American English.
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;METHOD&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I had to devise a way to quickly listen to “data” in context across a variety of accents, genders, and ages. I decided to use three sources: Youglish, PlayPhrase, and the TED Corpus of Spoken English (TCSE).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youglish.com/search/data/all?&#34; target=&#34;_blank&#34;&gt;Youglish&lt;/a&gt; allows you to search YouTube for a word or phrase and then listen to the phrase in context from many different videos, including online lectures, webinars, TED Talks, etc. What’s more, it allows you to filter the videos by accent: US, UK, or Australian.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://playphrase.me/#/search?q=data&#34; target=&#34;_blank&#34;&gt;PlayPhrase&lt;/a&gt; is similar to Youglish. However, rather than utilize YouTube, PlayPhrase mines popular TV shows (e.g. &lt;em&gt;Supernatural&lt;/em&gt;) and movies (e.g. &lt;em&gt;Star Trek&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yohasebe.com/tcse/&#34; target=&#34;_blank&#34;&gt;TCSE&lt;/a&gt; is also similar to the websites above. It utilizes only TED Talks (which also appear on Youglish).
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I first used Youglish, listening to around 20 examples of “data” in US, UK, and Australian English. I then listened to about 20 clips each from PlayPhrase and TCSE (being careful not to repeat TED Talks). In total, I had 100 observations of “data” in context. As I listened, I coded the pronunciation as 1 = /deɪtə/ and 2 = /dætə/; M for male and F for female; US, UK, AUS, or L2 for the accent; and &lt;40 or &gt;40 for a general (and very unscientific) guess about the age of the speaker.&lt;/p&gt;

&lt;p&gt;In regards to accents, while I recognize there is great variation among the accent categories, the accent codes are generalizations. A US accent represents anyone with a general North American accent. A UK accent represents any of the varieties of British pronunciation. AUS was used only for Youglish videos marked as Australian. Finally, L2 was used for speakers who were not from Anglophone countries (US, UK, IR, AU, NZ) and whose first language was likely not English (based solely on accent).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FINDINGS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;My findings were surprising.&lt;/p&gt;

&lt;p&gt;In regards to &lt;strong&gt;hypothesis 1&lt;/strong&gt;, that /dætə/ is more common, I was completely wrong (see Figure 1) . Across all accents, genders, and ages, /deɪtə/ is actually more common. This really surprised me. Even among those older than 40, including the elderly, /deɪtə/ was used common.&lt;/p&gt;

&lt;p&gt;In regards to &lt;strong&gt;hypothesis 2&lt;/strong&gt;, I was even more wrong (see Figure 2). Those with British accents used /deɪtə/ rather than the other varieties. The only two accents where I heard /dætə/ was the US / North American accent and the Australian accent. For the US / North American accent, /dætə/ was used only 33% of the time; in other words, /deɪtə/ is more common.&lt;/p&gt;

&lt;p&gt;While underrepresented in the sample (18 videos), it is important to note that /dæ tə/ seems most common in the Australian accent (44%). This is very surprising to me because of the close relationship between British and Australian English.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://i2.wp.com/www.anthonyschmidt.co/wp-content/uploads/2019/08/Overall@2x-100.jpg&#34; alt=&#34;Figure 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://i2.wp.com/www.anthonyschmidt.co/wp-content/uploads/2019/08/Accent-and-Gender@2x-100-1.jpg&#34; alt=&#34;Figure 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LIMITATIONS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Clearly, this is not a scientific study. The sample is small, does not represent accents equally, and is sampled online from online videos. However, it does give a general idea of what is the more common pronunciation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CONCLUSION&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the end, this was a fun exercise. I learned that my speech pattern of “data” as /dætə/ is not in line with other aspects of my speech that are more common: singular they, singular data, so, like, etc.&lt;/p&gt;

&lt;p&gt;Although I have a better idea of which pronunciation is more common, I still have no idea about the history of the word, when the shift occurred, and what facilitated it.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
